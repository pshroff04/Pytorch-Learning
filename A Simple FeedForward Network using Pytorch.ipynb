{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A typical training procedure for a neural network is as follows:\n",
    "\n",
    "Define the neural network that has some learnable parameters (or weights)\n",
    "Iterate over a dataset of inputs\n",
    "Process input through the network\n",
    "Compute the loss (how far is the output from being correct)\n",
    "Propagate gradients back into the networkâ€™s parameters\n",
    "Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) #Conv2d parameters: #channel_in, channel_out, kernel size \n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x    \n",
    "    \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ffnn = model()\n",
    "print(ffnn) #see the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the learnable parameters\n",
    "l = list(ffnn.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0670, -0.0426,  0.0892,  0.0375,  0.1500,  0.0769,  0.0445, -0.0166,\n",
      "         -0.1227,  0.1012]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(1,1,32,32)\n",
    "out = ffnn(t)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7606, 0.1782, 0.6753, 0.9203, 0.8952, 0.8738, 0.9695, 0.4205, 0.5126,\n",
      "         0.3479]])\n"
     ]
    }
   ],
   "source": [
    "target = target.view(1,-1)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFunction = nn.MSELoss()\n",
    "loss = costFunction(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4558, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Computation graph\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n",
    "ffnn.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([-0.0067,  0.0010,  0.0004, -0.0032,  0.0073,  0.0007])\n"
     ]
    }
   ],
   "source": [
    "#gradient of conv1 layer before gradient\n",
    "print(ffnn.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print(ffnn.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the parameter\n",
    "learning_rate = 0.001\n",
    "for f in ffnn.parameters():\n",
    "    f.data.sub_(learning_rate*f.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use any other optimizer\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(ffnn.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "out = ffnn(t)\n",
    "loss = costFunction(out, target)\n",
    "loss.backward()\n",
    "optimizer.step() #update the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.0546, -0.1184,  0.0429, -0.1313, -0.0570],\n",
       "           [ 0.0446,  0.1544,  0.1698, -0.0569,  0.1383],\n",
       "           [-0.0213,  0.1659, -0.1411, -0.1192, -0.0773],\n",
       "           [ 0.0457,  0.1573, -0.0105,  0.1066, -0.0191],\n",
       "           [-0.0864, -0.0465, -0.0838, -0.1686, -0.0662]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0696, -0.1745, -0.1891, -0.0568, -0.1134],\n",
       "           [ 0.0048,  0.0789,  0.1468,  0.1652,  0.0167],\n",
       "           [-0.1206, -0.1288,  0.0023,  0.1276,  0.1561],\n",
       "           [-0.1229, -0.1944,  0.0661,  0.1063,  0.0510],\n",
       "           [ 0.0936,  0.1287, -0.1423, -0.1465, -0.0178]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1786, -0.1462, -0.1645,  0.1352,  0.0487],\n",
       "           [ 0.0683, -0.1894, -0.1746, -0.0006,  0.0321],\n",
       "           [-0.0340,  0.0078, -0.1830,  0.1288, -0.0723],\n",
       "           [-0.0759, -0.1581,  0.1124, -0.0458, -0.1766],\n",
       "           [ 0.0570, -0.0219, -0.1381,  0.1339, -0.0287]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0170, -0.0462,  0.0200, -0.1292, -0.0942],\n",
       "           [ 0.0621, -0.1699, -0.0480,  0.0445, -0.1514],\n",
       "           [ 0.1066,  0.1947,  0.1240,  0.1275, -0.1055],\n",
       "           [ 0.1471, -0.0590,  0.0018, -0.1119,  0.0995],\n",
       "           [ 0.1528,  0.0443,  0.0401,  0.1745,  0.0842]]],\n",
       " \n",
       " \n",
       "         [[[-0.1565,  0.1897,  0.0337, -0.0221,  0.1532],\n",
       "           [-0.1213,  0.0862, -0.1339, -0.1636,  0.1625],\n",
       "           [ 0.1864, -0.1542, -0.0317,  0.0554, -0.0926],\n",
       "           [-0.0943, -0.1399,  0.0742,  0.0480, -0.0308],\n",
       "           [ 0.1638,  0.1351,  0.1147,  0.1056, -0.0923]]],\n",
       " \n",
       " \n",
       "         [[[-0.1655, -0.1057, -0.0953,  0.0602, -0.0070],\n",
       "           [ 0.1592, -0.1591, -0.1865, -0.1541,  0.1574],\n",
       "           [-0.0308,  0.1398,  0.1293, -0.1897, -0.1839],\n",
       "           [-0.0781, -0.0883,  0.1094, -0.0920, -0.1135],\n",
       "           [ 0.1046, -0.1891,  0.0770, -0.0094,  0.1817]]]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0628,  0.0639, -0.0872,  0.0417, -0.0925,  0.0088], requires_grad=True), Parameter containing:\n",
       " tensor([[[[ 0.0754,  0.0225,  0.0366, -0.0594,  0.0790],\n",
       "           [-0.0197,  0.0250, -0.0698,  0.0737,  0.0097],\n",
       "           [ 0.0054,  0.0423, -0.0364,  0.0518,  0.0570],\n",
       "           [-0.0595,  0.0697,  0.0675, -0.0562,  0.0145],\n",
       "           [ 0.0350, -0.0225,  0.0802, -0.0700,  0.0533]],\n",
       " \n",
       "          [[ 0.0250,  0.0225,  0.0096,  0.0024, -0.0015],\n",
       "           [ 0.0677, -0.0714,  0.0305, -0.0707, -0.0125],\n",
       "           [ 0.0640, -0.0444, -0.0421,  0.0756,  0.0810],\n",
       "           [-0.0164,  0.0365,  0.0800, -0.0384,  0.0477],\n",
       "           [ 0.0271, -0.0117,  0.0147,  0.0093, -0.0350]],\n",
       " \n",
       "          [[ 0.0305,  0.0618,  0.0005, -0.0623,  0.0274],\n",
       "           [-0.0051,  0.0095,  0.0138,  0.0344,  0.0204],\n",
       "           [-0.0029, -0.0064,  0.0454,  0.0816, -0.0247],\n",
       "           [-0.0599, -0.0018, -0.0448,  0.0027,  0.0119],\n",
       "           [-0.0799,  0.0233, -0.0747,  0.0053,  0.0783]],\n",
       " \n",
       "          [[-0.0495, -0.0593, -0.0720, -0.0071,  0.0582],\n",
       "           [ 0.0083,  0.0051,  0.0016,  0.0118, -0.0788],\n",
       "           [-0.0346,  0.0692, -0.0383,  0.0423,  0.0224],\n",
       "           [ 0.0003,  0.0264,  0.0032, -0.0779,  0.0026],\n",
       "           [ 0.0448, -0.0541,  0.0349,  0.0034, -0.0248]],\n",
       " \n",
       "          [[-0.0042, -0.0680,  0.0351, -0.0368, -0.0684],\n",
       "           [-0.0211,  0.0806, -0.0275,  0.0448, -0.0354],\n",
       "           [ 0.0333,  0.0142, -0.0598,  0.0116,  0.0641],\n",
       "           [ 0.0361,  0.0188, -0.0254, -0.0134, -0.0063],\n",
       "           [ 0.0097,  0.0324,  0.0049,  0.0213,  0.0784]],\n",
       " \n",
       "          [[ 0.0279, -0.0440, -0.0416, -0.0640,  0.0454],\n",
       "           [ 0.0413, -0.0695, -0.0511,  0.0702,  0.0212],\n",
       "           [ 0.0190, -0.0330,  0.0568, -0.0431, -0.0038],\n",
       "           [-0.0449, -0.0017,  0.0120, -0.0155, -0.0297],\n",
       "           [-0.0492,  0.0683,  0.0258, -0.0578, -0.0702]]],\n",
       " \n",
       " \n",
       "         [[[-0.0091, -0.0512,  0.0323, -0.0656,  0.0103],\n",
       "           [ 0.0060,  0.0145,  0.0650,  0.0126, -0.0503],\n",
       "           [-0.0285,  0.0013, -0.0698, -0.0311, -0.0522],\n",
       "           [-0.0342, -0.0546,  0.0596,  0.0066,  0.0544],\n",
       "           [-0.0160, -0.0395,  0.0277,  0.0108,  0.0695]],\n",
       " \n",
       "          [[-0.0560,  0.0353, -0.0367,  0.0793, -0.0109],\n",
       "           [ 0.0197,  0.0129,  0.0490, -0.0049,  0.0657],\n",
       "           [ 0.0075, -0.0637, -0.0389,  0.0049, -0.0457],\n",
       "           [ 0.0510, -0.0666, -0.0624, -0.0698,  0.0152],\n",
       "           [-0.0756, -0.0175, -0.0664,  0.0310, -0.0092]],\n",
       " \n",
       "          [[ 0.0028,  0.0624,  0.0467, -0.0152, -0.0375],\n",
       "           [-0.0467, -0.0227, -0.0080,  0.0368,  0.0303],\n",
       "           [ 0.0042, -0.0616,  0.0239,  0.0342, -0.0682],\n",
       "           [-0.0554,  0.0155,  0.0311, -0.0172,  0.0080],\n",
       "           [-0.0689, -0.0090, -0.0197,  0.0286, -0.0743]],\n",
       " \n",
       "          [[-0.0139,  0.0381, -0.0722,  0.0527,  0.0721],\n",
       "           [ 0.0329, -0.0393, -0.0039, -0.0724, -0.0286],\n",
       "           [ 0.0389, -0.0216,  0.0724, -0.0767, -0.0242],\n",
       "           [ 0.0147,  0.0543, -0.0196, -0.0091, -0.0444],\n",
       "           [-0.0586, -0.0632, -0.0279,  0.0154,  0.0013]],\n",
       " \n",
       "          [[-0.0698, -0.0679, -0.0516, -0.0279, -0.0192],\n",
       "           [-0.0609,  0.0754, -0.0001,  0.0441, -0.0812],\n",
       "           [ 0.0115,  0.0712,  0.0809,  0.0435, -0.0253],\n",
       "           [-0.0385, -0.0160,  0.0287, -0.0441,  0.0521],\n",
       "           [-0.0754,  0.0750, -0.0051, -0.0624,  0.0769]],\n",
       " \n",
       "          [[ 0.0102,  0.0411, -0.0729, -0.0796, -0.0756],\n",
       "           [-0.0131, -0.0300, -0.0664, -0.0685, -0.0040],\n",
       "           [-0.0124, -0.0498, -0.0415,  0.0791,  0.0118],\n",
       "           [ 0.0641, -0.0465, -0.0608, -0.0114,  0.0289],\n",
       "           [-0.0316,  0.0557,  0.0066,  0.0595, -0.0139]]],\n",
       " \n",
       " \n",
       "         [[[-0.0042,  0.0147, -0.0192,  0.0097,  0.0547],\n",
       "           [ 0.0035, -0.0602,  0.0342, -0.0437,  0.0433],\n",
       "           [-0.0467, -0.0505,  0.0030,  0.0276, -0.0457],\n",
       "           [-0.0250, -0.0421, -0.0389,  0.0203,  0.0801],\n",
       "           [-0.0493, -0.0619, -0.0513,  0.0343, -0.0548]],\n",
       " \n",
       "          [[ 0.0379,  0.0627,  0.0610,  0.0799,  0.0310],\n",
       "           [-0.0320, -0.0746,  0.0121, -0.0757,  0.0047],\n",
       "           [-0.0166,  0.0546, -0.0233, -0.0607, -0.0588],\n",
       "           [-0.0443,  0.0708, -0.0339, -0.0728,  0.0693],\n",
       "           [-0.0188,  0.0663,  0.0715,  0.0663,  0.0803]],\n",
       " \n",
       "          [[-0.0543, -0.0474,  0.0471, -0.0437,  0.0151],\n",
       "           [-0.0065, -0.0788,  0.0239, -0.0566,  0.0573],\n",
       "           [-0.0138,  0.0763,  0.0619,  0.0786,  0.0186],\n",
       "           [ 0.0038,  0.0474,  0.0617, -0.0767, -0.0689],\n",
       "           [ 0.0534,  0.0171,  0.0648,  0.0610, -0.0807]],\n",
       " \n",
       "          [[ 0.0071,  0.0777,  0.0382,  0.0225,  0.0358],\n",
       "           [-0.0228,  0.0605,  0.0279, -0.0029, -0.0608],\n",
       "           [-0.0278,  0.0561,  0.0759, -0.0805, -0.0231],\n",
       "           [-0.0057, -0.0534,  0.0680, -0.0034, -0.0070],\n",
       "           [ 0.0464,  0.0305, -0.0588,  0.0561,  0.0711]],\n",
       " \n",
       "          [[-0.0138,  0.0317,  0.0393,  0.0129, -0.0277],\n",
       "           [ 0.0334, -0.0134,  0.0051,  0.0491, -0.0755],\n",
       "           [-0.0666,  0.0123, -0.0647, -0.0426,  0.0324],\n",
       "           [-0.0720,  0.0155,  0.0636,  0.0303,  0.0768],\n",
       "           [ 0.0037,  0.0342, -0.0085, -0.0467,  0.0182]],\n",
       " \n",
       "          [[-0.0653,  0.0474, -0.0682,  0.0302, -0.0755],\n",
       "           [ 0.0763,  0.0648, -0.0276,  0.0247,  0.0692],\n",
       "           [ 0.0617,  0.0456,  0.0697,  0.0340,  0.0607],\n",
       "           [-0.0311,  0.0454, -0.0208,  0.0518,  0.0252],\n",
       "           [ 0.0251, -0.0276, -0.0765,  0.0733,  0.0542]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0414,  0.0642,  0.0077,  0.0595, -0.0654],\n",
       "           [-0.0576, -0.0496,  0.0657,  0.0555, -0.0801],\n",
       "           [ 0.0778, -0.0293, -0.0174,  0.0788, -0.0743],\n",
       "           [-0.0080,  0.0189, -0.0485,  0.0015,  0.0654],\n",
       "           [ 0.0364, -0.0368, -0.0597,  0.0258,  0.0129]],\n",
       " \n",
       "          [[-0.0019,  0.0588,  0.0164,  0.0290,  0.0466],\n",
       "           [ 0.0804, -0.0771,  0.0266, -0.0270, -0.0746],\n",
       "           [-0.0153, -0.0336,  0.0457, -0.0792, -0.0684],\n",
       "           [ 0.0019,  0.0726,  0.0002,  0.0453,  0.0150],\n",
       "           [-0.0379, -0.0701, -0.0202,  0.0807,  0.0194]],\n",
       " \n",
       "          [[-0.0471, -0.0352,  0.0528,  0.0611, -0.0682],\n",
       "           [-0.0250,  0.0682,  0.0798, -0.0749, -0.0269],\n",
       "           [ 0.0680,  0.0792, -0.0595,  0.0265, -0.0458],\n",
       "           [-0.0257, -0.0032, -0.0091,  0.0599, -0.0397],\n",
       "           [ 0.0228, -0.0471, -0.0311, -0.0319,  0.0045]],\n",
       " \n",
       "          [[ 0.0576,  0.0429, -0.0266,  0.0504,  0.0216],\n",
       "           [ 0.0528, -0.0389, -0.0254,  0.0336, -0.0764],\n",
       "           [-0.0278,  0.0200,  0.0385,  0.0243, -0.0464],\n",
       "           [-0.0482, -0.0314,  0.0174,  0.0479, -0.0206],\n",
       "           [-0.0111,  0.0259,  0.0752, -0.0671,  0.0468]],\n",
       " \n",
       "          [[-0.0404, -0.0099, -0.0593,  0.0752,  0.0032],\n",
       "           [-0.0205,  0.0321,  0.0786, -0.0751, -0.0684],\n",
       "           [ 0.0155, -0.0444,  0.0206,  0.0535, -0.0705],\n",
       "           [-0.0668, -0.0765, -0.0279,  0.0458, -0.0472],\n",
       "           [ 0.0494,  0.0632, -0.0468, -0.0362,  0.0471]],\n",
       " \n",
       "          [[ 0.0201,  0.0606, -0.0298,  0.0047, -0.0402],\n",
       "           [-0.0295,  0.0318,  0.0626,  0.0816, -0.0621],\n",
       "           [-0.0572, -0.0234, -0.0691, -0.0239, -0.0015],\n",
       "           [-0.0193, -0.0582, -0.0410,  0.0262, -0.0537],\n",
       "           [-0.0578,  0.0739,  0.0014,  0.0791, -0.0526]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0425,  0.0778, -0.0245,  0.0741, -0.0343],\n",
       "           [ 0.0718,  0.0313,  0.0403,  0.0231,  0.0684],\n",
       "           [-0.0446, -0.0752, -0.0692,  0.0280,  0.0813],\n",
       "           [ 0.0107, -0.0085, -0.0248, -0.0070,  0.0352],\n",
       "           [-0.0128,  0.0160, -0.0623,  0.0716, -0.0503]],\n",
       " \n",
       "          [[-0.0553, -0.0174,  0.0180,  0.0106,  0.0057],\n",
       "           [ 0.0189,  0.0697, -0.0419,  0.0131,  0.0574],\n",
       "           [ 0.0448, -0.0648, -0.0435,  0.0225,  0.0396],\n",
       "           [-0.0547, -0.0115, -0.0528,  0.0425,  0.0555],\n",
       "           [ 0.0527, -0.0707,  0.0591, -0.0685, -0.0009]],\n",
       " \n",
       "          [[ 0.0512, -0.0583,  0.0700, -0.0333, -0.0027],\n",
       "           [-0.0048,  0.0570,  0.0175, -0.0801, -0.0093],\n",
       "           [ 0.0442,  0.0784, -0.0365,  0.0339, -0.0812],\n",
       "           [ 0.0138,  0.0631,  0.0706, -0.0291, -0.0768],\n",
       "           [-0.0646,  0.0367,  0.0542, -0.0214,  0.0319]],\n",
       " \n",
       "          [[ 0.0207, -0.0484,  0.0392, -0.0081,  0.0403],\n",
       "           [ 0.0170,  0.0697,  0.0499,  0.0307,  0.0082],\n",
       "           [ 0.0430, -0.0583, -0.0536, -0.0597,  0.0485],\n",
       "           [-0.0157, -0.0477,  0.0120,  0.0067, -0.0445],\n",
       "           [-0.0381, -0.0802, -0.0603,  0.0482,  0.0189]],\n",
       " \n",
       "          [[-0.0223,  0.0813,  0.0535, -0.0421,  0.0570],\n",
       "           [-0.0218, -0.0210, -0.0652,  0.0720,  0.0076],\n",
       "           [-0.0699,  0.0379,  0.0233, -0.0582,  0.0064],\n",
       "           [ 0.0146,  0.0697, -0.0811, -0.0676,  0.0805],\n",
       "           [-0.0036, -0.0546, -0.0213, -0.0792,  0.0489]],\n",
       " \n",
       "          [[ 0.0101,  0.0243, -0.0042, -0.0378,  0.0333],\n",
       "           [-0.0006, -0.0723, -0.0776,  0.0100, -0.0677],\n",
       "           [-0.0183, -0.0130,  0.0579,  0.0219, -0.0773],\n",
       "           [-0.0001, -0.0624,  0.0531,  0.0138,  0.0394],\n",
       "           [ 0.0578, -0.0376,  0.0061, -0.0563, -0.0265]]],\n",
       " \n",
       " \n",
       "         [[[-0.0174, -0.0805, -0.0596, -0.0515, -0.0140],\n",
       "           [ 0.0072,  0.0222,  0.0268, -0.0108, -0.0434],\n",
       "           [ 0.0397, -0.0363,  0.0655,  0.0172,  0.0636],\n",
       "           [-0.0219,  0.0187, -0.0008,  0.0234,  0.0065],\n",
       "           [ 0.0696, -0.0189,  0.0357, -0.0306,  0.0081]],\n",
       " \n",
       "          [[ 0.0797, -0.0058,  0.0107, -0.0186,  0.0666],\n",
       "           [ 0.0394,  0.0685,  0.0805,  0.0566, -0.0315],\n",
       "           [ 0.0019, -0.0342, -0.0032, -0.0314, -0.0493],\n",
       "           [ 0.0466, -0.0708, -0.0623, -0.0607, -0.0173],\n",
       "           [ 0.0485, -0.0548, -0.0007, -0.0246,  0.0504]],\n",
       " \n",
       "          [[-0.0051, -0.0159, -0.0683, -0.0289, -0.0520],\n",
       "           [ 0.0553, -0.0336, -0.0206, -0.0457,  0.0771],\n",
       "           [-0.0377,  0.0596, -0.0629,  0.0412,  0.0130],\n",
       "           [-0.0460, -0.0442, -0.0298,  0.0619, -0.0316],\n",
       "           [ 0.0000,  0.0104,  0.0403,  0.0488, -0.0552]],\n",
       " \n",
       "          [[ 0.0123,  0.0707, -0.0024, -0.0815,  0.0182],\n",
       "           [ 0.0017, -0.0217,  0.0185, -0.0257, -0.0068],\n",
       "           [ 0.0105, -0.0116, -0.0244,  0.0733,  0.0094],\n",
       "           [ 0.0109, -0.0082, -0.0578, -0.0334,  0.0053],\n",
       "           [-0.0200,  0.0343, -0.0014, -0.0044, -0.0172]],\n",
       " \n",
       "          [[ 0.0579,  0.0414, -0.0020,  0.0542,  0.0804],\n",
       "           [ 0.0473,  0.0360, -0.0398,  0.0174, -0.0529],\n",
       "           [-0.0763, -0.0696,  0.0023,  0.0586, -0.0213],\n",
       "           [-0.0656, -0.0168,  0.0588,  0.0108, -0.0063],\n",
       "           [-0.0122, -0.0285, -0.0772,  0.0425,  0.0657]],\n",
       " \n",
       "          [[ 0.0065,  0.0427,  0.0002,  0.0074, -0.0813],\n",
       "           [ 0.0496, -0.0468,  0.0781, -0.0641,  0.0137],\n",
       "           [-0.0753, -0.0079,  0.0664,  0.0079, -0.0368],\n",
       "           [-0.0319, -0.0205,  0.0305,  0.0473, -0.0666],\n",
       "           [-0.0091,  0.0398, -0.0466, -0.0157, -0.0155]]]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0288,  0.0739,  0.0372, -0.0506,  0.0323, -0.0413,  0.0146, -0.0012,\n",
       "         -0.0134, -0.0153,  0.0424, -0.0081,  0.0179, -0.0201, -0.0150,  0.0734],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0136,  0.0391,  0.0438,  ..., -0.0315,  0.0465,  0.0009],\n",
       "         [ 0.0170,  0.0425,  0.0011,  ...,  0.0244,  0.0222,  0.0193],\n",
       "         [-0.0175, -0.0396,  0.0460,  ...,  0.0382,  0.0089,  0.0151],\n",
       "         ...,\n",
       "         [-0.0351,  0.0061,  0.0050,  ...,  0.0322,  0.0488, -0.0483],\n",
       "         [ 0.0232,  0.0185,  0.0409,  ...,  0.0262,  0.0391, -0.0444],\n",
       "         [ 0.0170, -0.0007, -0.0457,  ..., -0.0399, -0.0291,  0.0221]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0026, -0.0005,  0.0086,  0.0049,  0.0168, -0.0196,  0.0339,  0.0379,\n",
       "         -0.0183,  0.0230,  0.0002, -0.0457, -0.0308, -0.0204,  0.0051,  0.0478,\n",
       "         -0.0435,  0.0183,  0.0344,  0.0473, -0.0030, -0.0098, -0.0002,  0.0147,\n",
       "         -0.0112, -0.0297,  0.0416, -0.0405,  0.0237,  0.0242, -0.0015, -0.0302,\n",
       "          0.0497,  0.0487, -0.0290, -0.0125, -0.0059, -0.0321,  0.0484,  0.0203,\n",
       "         -0.0210, -0.0296, -0.0207, -0.0467, -0.0132,  0.0333, -0.0028, -0.0012,\n",
       "         -0.0093, -0.0436, -0.0131,  0.0462, -0.0424,  0.0495, -0.0273,  0.0140,\n",
       "          0.0445, -0.0071,  0.0115,  0.0113, -0.0215, -0.0213, -0.0263,  0.0117,\n",
       "          0.0500, -0.0388,  0.0357, -0.0378,  0.0130, -0.0418,  0.0198,  0.0255,\n",
       "         -0.0084,  0.0127, -0.0455, -0.0251,  0.0421, -0.0180,  0.0082,  0.0196,\n",
       "         -0.0393,  0.0135,  0.0089,  0.0107,  0.0080, -0.0467, -0.0454,  0.0373,\n",
       "         -0.0162, -0.0095, -0.0394, -0.0455,  0.0017, -0.0426, -0.0171, -0.0012,\n",
       "          0.0108, -0.0427,  0.0442, -0.0482,  0.0251,  0.0113, -0.0106, -0.0180,\n",
       "          0.0251, -0.0286,  0.0129,  0.0163,  0.0305, -0.0219,  0.0152, -0.0137,\n",
       "         -0.0403,  0.0389,  0.0298,  0.0090,  0.0136, -0.0146,  0.0250, -0.0138],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0462,  0.0905,  0.0803,  ..., -0.0321, -0.0334,  0.0913],\n",
       "         [-0.0172,  0.0388,  0.0047,  ...,  0.0301,  0.0675, -0.0462],\n",
       "         [-0.0764,  0.0147, -0.0035,  ..., -0.0588, -0.0475,  0.0276],\n",
       "         ...,\n",
       "         [-0.0300, -0.0862, -0.0641,  ...,  0.0166,  0.0353,  0.0519],\n",
       "         [-0.0573,  0.0535, -0.0217,  ..., -0.0322, -0.0795,  0.0595],\n",
       "         [ 0.0044, -0.0286,  0.0402,  ..., -0.0306,  0.0666, -0.0069]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0677,  0.0137, -0.0526, -0.0711,  0.0165, -0.0477,  0.0764,  0.0322,\n",
       "         -0.0773,  0.0843,  0.0886, -0.0804,  0.0235, -0.0631,  0.0177, -0.0480,\n",
       "         -0.0480,  0.0677,  0.0774, -0.0154, -0.0492,  0.0084, -0.0845,  0.0573,\n",
       "          0.0914,  0.0510, -0.0821,  0.0330, -0.0287, -0.0388, -0.0101,  0.0282,\n",
       "         -0.0008,  0.0719,  0.0832,  0.0646,  0.0002,  0.0721,  0.0693,  0.0622,\n",
       "          0.0313, -0.0492,  0.0369,  0.0125,  0.0493,  0.0560,  0.0078,  0.0112,\n",
       "          0.0284, -0.0695,  0.0791,  0.0820, -0.0704, -0.0172,  0.0676, -0.0007,\n",
       "          0.0518,  0.0234, -0.0438, -0.0737, -0.0585, -0.0774, -0.0144,  0.0446,\n",
       "          0.0075,  0.0195, -0.0288,  0.0298,  0.0656,  0.0505,  0.0224,  0.0770,\n",
       "         -0.0236,  0.0591,  0.0408,  0.0697, -0.0905, -0.0745,  0.0547,  0.0253,\n",
       "         -0.0385,  0.0360,  0.0110,  0.0011], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0092, -0.0658,  0.0222, -0.0468, -0.1006,  0.0498, -0.0598,  0.0127,\n",
       "           0.0106,  0.0798,  0.0024, -0.0764,  0.0082,  0.0480, -0.0411,  0.0273,\n",
       "          -0.0857,  0.0516, -0.0542, -0.0695, -0.0290, -0.0103, -0.0441, -0.0792,\n",
       "          -0.0133, -0.0485,  0.1050, -0.0248, -0.0937,  0.0406, -0.1022, -0.0071,\n",
       "          -0.0729, -0.0721,  0.0825, -0.0189,  0.0935,  0.0964,  0.0489, -0.0776,\n",
       "          -0.0911, -0.0552,  0.0153,  0.0740,  0.0512,  0.0262,  0.0133,  0.0435,\n",
       "           0.0943,  0.0293,  0.0548,  0.0136,  0.0536, -0.0191,  0.0131, -0.0449,\n",
       "          -0.0403, -0.0606,  0.0269,  0.0814,  0.0491, -0.0274, -0.0810, -0.0212,\n",
       "           0.0174, -0.0299,  0.0652,  0.0256,  0.0740, -0.0143, -0.1051, -0.1028,\n",
       "           0.0022, -0.0923,  0.0424, -0.0913,  0.0800,  0.0872,  0.0522, -0.0284,\n",
       "           0.0460, -0.0646,  0.0452, -0.0055],\n",
       "         [-0.0857, -0.0815,  0.0891, -0.0660, -0.0022, -0.0867,  0.0116, -0.0931,\n",
       "           0.0068,  0.0101,  0.0188,  0.1003,  0.0275,  0.0839,  0.0671, -0.0820,\n",
       "          -0.0923, -0.0226, -0.0591, -0.0522,  0.0118, -0.0620, -0.0678, -0.0154,\n",
       "           0.0855, -0.0435, -0.0401, -0.0236,  0.0701,  0.0871,  0.0829,  0.0364,\n",
       "          -0.0189,  0.0115,  0.0049, -0.0023, -0.0083,  0.0142,  0.0900, -0.0298,\n",
       "           0.0274, -0.0049, -0.0266, -0.0646, -0.0968, -0.0765, -0.0619,  0.0913,\n",
       "           0.0258,  0.0314,  0.1029,  0.0917,  0.0248,  0.0886,  0.0468, -0.0509,\n",
       "           0.0769,  0.0298,  0.0752, -0.0681,  0.0293,  0.0781, -0.0203,  0.0553,\n",
       "          -0.0919,  0.0260,  0.0258,  0.0810, -0.0268,  0.0361, -0.0195, -0.0072,\n",
       "          -0.0217,  0.0872, -0.0318, -0.0062, -0.0400,  0.0748,  0.0843, -0.0553,\n",
       "           0.0462,  0.0815, -0.1044, -0.0271],\n",
       "         [-0.0694, -0.1041,  0.0026, -0.0070,  0.0492,  0.0572,  0.0309, -0.0256,\n",
       "           0.0397, -0.0544,  0.0493,  0.0125,  0.0965, -0.0711, -0.0969, -0.0417,\n",
       "          -0.0586, -0.0891, -0.0439, -0.0744,  0.0201,  0.0863, -0.0625, -0.0890,\n",
       "           0.0809, -0.0857,  0.0862,  0.0478, -0.0375, -0.0374, -0.1027, -0.0805,\n",
       "          -0.0887, -0.0582,  0.1038,  0.0350, -0.0784, -0.0132, -0.0303, -0.1020,\n",
       "           0.0391,  0.0496, -0.1049,  0.0770, -0.0724, -0.0994, -0.0886, -0.0180,\n",
       "           0.0384,  0.0556,  0.0871,  0.0414,  0.0114, -0.0008,  0.0402,  0.0638,\n",
       "          -0.0097,  0.0345, -0.0977, -0.0700, -0.0181,  0.0972, -0.0707,  0.0257,\n",
       "          -0.0256,  0.0157, -0.0799,  0.1060, -0.1069,  0.0981, -0.0528, -0.0669,\n",
       "           0.0779,  0.0623,  0.0300,  0.0587,  0.0123, -0.0224, -0.0645,  0.0407,\n",
       "          -0.0167,  0.0797,  0.0656, -0.0131],\n",
       "         [-0.0799, -0.0189,  0.0837, -0.0925,  0.0373,  0.0140, -0.0163,  0.0671,\n",
       "          -0.0334, -0.0746, -0.0652, -0.0080,  0.0608,  0.0346, -0.0571, -0.0912,\n",
       "           0.0561,  0.0730, -0.1069, -0.0320,  0.0755,  0.1091,  0.0547,  0.0031,\n",
       "           0.0941, -0.0866, -0.0502, -0.0008,  0.0258, -0.0703,  0.0330, -0.0911,\n",
       "           0.0010, -0.0882,  0.1025,  0.0354,  0.0613,  0.0083, -0.0723, -0.0730,\n",
       "           0.0539,  0.0809,  0.0502,  0.1015, -0.0807, -0.0904, -0.0143, -0.0267,\n",
       "          -0.0962, -0.0697, -0.0855, -0.0480,  0.0461,  0.1015, -0.0098, -0.0323,\n",
       "          -0.0651, -0.0858, -0.0113, -0.0653,  0.0793,  0.0304,  0.0879,  0.0178,\n",
       "          -0.0843,  0.0188, -0.0868,  0.1076,  0.0372, -0.0147,  0.0827, -0.0819,\n",
       "          -0.0846, -0.0071,  0.0079,  0.0544,  0.0431, -0.0318, -0.0354, -0.0245,\n",
       "           0.0629,  0.0100, -0.0888,  0.0026],\n",
       "         [ 0.0496,  0.0471,  0.0237, -0.0778, -0.0022,  0.0037, -0.0301,  0.0963,\n",
       "           0.0221,  0.1040,  0.1037, -0.0331, -0.0151, -0.0036,  0.1024,  0.0495,\n",
       "          -0.1076, -0.1007,  0.0862,  0.1059, -0.0867, -0.0563, -0.0827, -0.0515,\n",
       "          -0.0172, -0.1072,  0.0804,  0.0308, -0.0430, -0.0934,  0.0700,  0.0453,\n",
       "          -0.0536,  0.0789, -0.0862,  0.0043,  0.0783, -0.0402,  0.0584,  0.0598,\n",
       "          -0.0861, -0.1024, -0.0079, -0.0727, -0.0409, -0.0282,  0.0339,  0.0148,\n",
       "          -0.0375, -0.0070, -0.0255,  0.0334,  0.1019,  0.0346,  0.0902,  0.0230,\n",
       "          -0.0106, -0.0979, -0.0888, -0.0278, -0.0061,  0.0103, -0.1000, -0.0280,\n",
       "           0.0598, -0.0535,  0.0686, -0.1010, -0.0872, -0.0085,  0.0373,  0.0823,\n",
       "           0.0440,  0.0272, -0.0334,  0.0237,  0.0551, -0.0682,  0.1068,  0.0826,\n",
       "          -0.0784,  0.0196,  0.0567,  0.0879],\n",
       "         [ 0.0617,  0.0398, -0.0672, -0.0814,  0.0568,  0.0252,  0.0522,  0.0006,\n",
       "           0.0922, -0.1029, -0.0111,  0.0362, -0.0617, -0.0262, -0.0603, -0.1010,\n",
       "           0.0467,  0.0364, -0.0471,  0.0837, -0.0325,  0.0786, -0.0780,  0.0397,\n",
       "           0.0288,  0.0438, -0.0982,  0.0947,  0.0573, -0.0002, -0.0477,  0.0753,\n",
       "          -0.0758,  0.1075,  0.0151, -0.0521, -0.1068,  0.0201, -0.0668, -0.0681,\n",
       "          -0.0608, -0.0760,  0.0941, -0.0501,  0.1050,  0.0532,  0.0833,  0.1079,\n",
       "           0.0343, -0.0338, -0.0879,  0.0166,  0.0328,  0.0597, -0.0939, -0.0464,\n",
       "          -0.0602,  0.0445,  0.0553,  0.0199, -0.0892, -0.0681, -0.0925, -0.0933,\n",
       "           0.0484, -0.0961, -0.0858,  0.0313,  0.0966, -0.0985, -0.0125, -0.1085,\n",
       "           0.0226,  0.0456, -0.0666, -0.0039, -0.0746,  0.0274,  0.0320,  0.0246,\n",
       "           0.0314, -0.0206, -0.1041, -0.1054],\n",
       "         [-0.0647,  0.0923, -0.0797, -0.0280, -0.1047, -0.0117,  0.0357, -0.0845,\n",
       "          -0.0544, -0.0769,  0.0386, -0.0475, -0.1038, -0.1030, -0.0538, -0.0429,\n",
       "           0.0120, -0.0442,  0.0691, -0.0948,  0.0178,  0.0860,  0.0390,  0.0319,\n",
       "           0.0251,  0.1030, -0.0929,  0.0169,  0.0305,  0.0735, -0.0106,  0.1045,\n",
       "           0.0880, -0.0397, -0.0563, -0.0221,  0.0236,  0.0919, -0.0900, -0.0462,\n",
       "          -0.0152, -0.0023,  0.0641,  0.0192,  0.0902,  0.0406, -0.0241,  0.0604,\n",
       "          -0.0459, -0.0533,  0.0717,  0.0064, -0.0041, -0.0900,  0.0899, -0.0517,\n",
       "          -0.0685, -0.0881, -0.0398, -0.0469, -0.0473,  0.0712, -0.0842,  0.0757,\n",
       "           0.0476, -0.0882, -0.0872,  0.0270, -0.0703, -0.0729, -0.0325,  0.0329,\n",
       "           0.0764, -0.0395, -0.0585, -0.0723,  0.0668, -0.0775,  0.0431,  0.0174,\n",
       "          -0.0275, -0.0728,  0.0592,  0.0971],\n",
       "         [ 0.0320, -0.0296, -0.0625,  0.0756, -0.1003, -0.1070,  0.0108, -0.1032,\n",
       "           0.0179, -0.0893,  0.0647, -0.0539, -0.0336,  0.0252, -0.0289,  0.0523,\n",
       "          -0.0617,  0.0143,  0.1060,  0.0814,  0.0582,  0.0127, -0.0470,  0.0373,\n",
       "           0.0403, -0.1005, -0.0191,  0.0212, -0.0727, -0.0580,  0.1063, -0.0734,\n",
       "          -0.0745,  0.0403, -0.0159,  0.0532, -0.0746, -0.0118, -0.0195, -0.0929,\n",
       "           0.0994,  0.0756,  0.0805,  0.0471,  0.0282, -0.1048,  0.0901,  0.0633,\n",
       "           0.0476, -0.0656,  0.0829, -0.0484, -0.1077,  0.0982, -0.0236,  0.0330,\n",
       "           0.0755,  0.0820, -0.1056, -0.0672,  0.0481, -0.0230,  0.0497,  0.0437,\n",
       "          -0.0145, -0.0430,  0.0728,  0.0651, -0.0793,  0.0804, -0.0899,  0.0920,\n",
       "           0.0760,  0.0725,  0.1002,  0.0754, -0.0381, -0.0883,  0.1008,  0.1051,\n",
       "          -0.0101,  0.0107,  0.0627,  0.0220],\n",
       "         [-0.0159,  0.0316,  0.0970, -0.0120,  0.0211, -0.0297,  0.0819,  0.0632,\n",
       "           0.0813, -0.0101, -0.0014, -0.0542,  0.0345,  0.1051, -0.0385,  0.0792,\n",
       "           0.0585,  0.0108, -0.0414,  0.0992, -0.0597, -0.0041,  0.0029,  0.0024,\n",
       "           0.0854, -0.0574,  0.0566, -0.0363, -0.0437, -0.0105,  0.0992,  0.0159,\n",
       "           0.0489, -0.0892,  0.0733,  0.0025, -0.0975,  0.0102, -0.0477, -0.1036,\n",
       "           0.0912, -0.0707, -0.0863,  0.0544, -0.0206, -0.0859, -0.0360,  0.0702,\n",
       "           0.0107,  0.0723,  0.0626, -0.0854,  0.1019, -0.1004, -0.0035,  0.0375,\n",
       "          -0.0553, -0.0876,  0.0288,  0.0151, -0.0916, -0.0270, -0.0785, -0.0135,\n",
       "          -0.0518,  0.0141, -0.0580, -0.0724,  0.0710,  0.0309,  0.0870, -0.0274,\n",
       "           0.0719, -0.0486,  0.1008, -0.0005, -0.0905, -0.1008, -0.0068, -0.0077,\n",
       "          -0.0362, -0.0386, -0.0469, -0.1076],\n",
       "         [ 0.0174, -0.0763, -0.0652, -0.0807, -0.0423, -0.0292,  0.0284, -0.0927,\n",
       "           0.0019, -0.0714, -0.0626,  0.0694, -0.0039, -0.0904,  0.0420,  0.0012,\n",
       "           0.0603, -0.0761, -0.0834,  0.1012, -0.0682,  0.0321,  0.0720,  0.0822,\n",
       "           0.0888,  0.0212,  0.0999, -0.0216,  0.0095,  0.0846,  0.0507, -0.0224,\n",
       "           0.0174,  0.0501, -0.0755, -0.0787,  0.0863,  0.0351,  0.0754, -0.0346,\n",
       "           0.0844, -0.0487,  0.0453, -0.0869,  0.0329, -0.0328, -0.0084,  0.0654,\n",
       "          -0.0775,  0.0777, -0.0415, -0.0476, -0.0284, -0.0601,  0.0581,  0.0107,\n",
       "           0.0265,  0.0777, -0.1031, -0.0043, -0.0492, -0.0638, -0.0682,  0.1061,\n",
       "           0.0203, -0.0451, -0.0600,  0.0189,  0.0526, -0.0430,  0.0095,  0.0445,\n",
       "           0.0050,  0.0216, -0.0885,  0.0291,  0.0443, -0.0012,  0.0414,  0.0044,\n",
       "          -0.0324,  0.1025,  0.0249,  0.0010]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0676, -0.0712,  0.0986,  0.0766,  0.1096,  0.1077,  0.0441, -0.0640,\n",
       "         -0.1028,  0.0996], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ffnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
