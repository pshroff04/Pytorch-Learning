{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile EncDec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "For 0 epoch,  5000 minibatch, average loss is 0.01871\n",
      "For 0 epoch, 10000 minibatch, average loss is 0.00689\n",
      "For 1 epoch,  5000 minibatch, average loss is 0.00537\n",
      "For 1 epoch, 10000 minibatch, average loss is 0.00471\n",
      "For 2 epoch,  5000 minibatch, average loss is 0.00439\n",
      "For 2 epoch, 10000 minibatch, average loss is 0.00421\n",
      "For 3 epoch,  5000 minibatch, average loss is 0.00414\n",
      "For 3 epoch, 10000 minibatch, average loss is 0.00409\n",
      "For 4 epoch,  5000 minibatch, average loss is 0.00404\n",
      "For 4 epoch, 10000 minibatch, average loss is 0.00404\n",
      "Test Set Loss 0.003993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,4,3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4,8,3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8,16,3, stride =2, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(16,8,4, stride =2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(8,4,4, stride =2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(4,3,4, stride =2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))      \n",
    "        x = self.deconv3(x)\n",
    "        return x\n",
    "\n",
    "### Create an instance of the Net class\n",
    "net = Net()\n",
    "\n",
    "## Loading the training and test sets\n",
    "# Converting the images for PILImage to tensor, so they can be accepted as the input to the network\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)\n",
    "\n",
    "### Define the loss and create your optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005)\n",
    "\n",
    "### Main training loop\n",
    "for epoch in range(5):\n",
    "    total_batch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        ## Getting the input and the target from the training set\n",
    "        input, dummy = data\n",
    "        target = input\n",
    "        out = net(input)\n",
    "        loss = criterion(out, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_batch_loss += loss.item()\n",
    "\n",
    "    #print('For %d epoch, average loss is %.3f'%(epoch, total_batch_loss/10000))\n",
    "        \n",
    "        if (i+1)%5000 == 0 and i!=0 :\n",
    "            print('For %d epoch, %5d minibatch, average loss is %.5f'%(epoch, (i+1), total_batch_loss/5000))\n",
    "            total_batch_loss = 0.0\n",
    "\n",
    "\n",
    "### Testing the network on 10,000 test images and computing the loss\n",
    "testLoss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        input, dummy = data\n",
    "        target = input\n",
    "        out = net(target)\n",
    "        loss = criterion(out, target)\n",
    "        testLoss += loss.item()\n",
    "    print('Test Set Loss %.6f' %(testLoss/2000))\n",
    "\n",
    "### Displaying or saving the results as well as the ground truth images for the first five images in the test set\n",
    "\n",
    "with torch.no_grad():\n",
    "    testiterator = iter(testloader)\n",
    "    o, _ = testiterator.next()\n",
    "    testout = net(o)\n",
    "\n",
    "#Display\n",
    "plt.imshow(torchvision.utils.make_grid(testout).numpy().transpose((1,2,0)))\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(o).numpy().transpose((1,2,0)))\n",
    "plt.show()\n",
    "\n",
    "#save\n",
    "torchvision.utils.save_image(torch.cat((testout,o)), \"EncDec.png\", nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
